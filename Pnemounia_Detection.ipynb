{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim\n",
    "To Attain the best accuracy of detecting pneumonia through CNN and Chest X-Ray Images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description -\n",
    "Pneumonia is an inflammatory condition of the lung primarily affecting the small air sacs known as alveoli. Symptoms typically include some combination of productive or dry cough, chest pain, fever, and difficulty breathing. The severity of the condition is variable. Pneumonia is usually caused by infection with viruses or bacteria, and less commonly by other microorganisms. Identifying the responsible pathogen can be difficult. Diagnosis is often based on symptoms and physical examination. Chest X-rays, blood tests, and culture of the sputum may help confirm the diagnosis. The disease may be classified by where it was acquired, such as community- or hospital-acquired or healthcare-associated pneumonia. Risk factors for pneumonia include cystic fibrosis, chronic obstructive pulmonary disease (COPD), sickle cell disease, asthma, diabetes, heart failure, a history of smoking, a poor ability to cough (such as following a stroke), and a weak immune system.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://dk4fkkwa4o9l0.cloudfront.net/production/uploads/article/image/1321/PNM.png\" width=\"500px\" height=\"500px\">\n",
    "</div>\n",
    "\n",
    "People with infectious pneumonia often have a productive cough, fever accompanied by shaking chills, shortness of breath, sharp or stabbing chest pain during deep breaths, and an increased rate of breathing. In elderly people, confusion may be the most prominent sign."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the dataset -\n",
    "The dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia/Normal). Chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children’s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients’ routine clinical care. For the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Dataset -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = './input/chest_xray/train/'\n",
    "test = './input/chest_xray/test/'\n",
    "val = './input/chest_xray/val/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization of train -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_num = len(os.listdir(os.path.join(train, 'PNEUMONIA')))\n",
    "print(\"Pneumonia: \",pneumonia_num)\n",
    "normal_num = len(os.listdir(os.path.join(train, 'NORMAL')))\n",
    "print(\"Normal: \",normal_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization of test -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_num = len(os.listdir(os.path.join(test, 'PNEUMONIA')))\n",
    "print(\"Pneumonia: \",pneumonia_num)\n",
    "normal_num = len(os.listdir(os.path.join(test, 'NORMAL')))\n",
    "print(\"Normal: \",normal_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization of val -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_num = len(os.listdir(os.path.join(test, 'PNEUMONIA')))\n",
    "print(\"Pneumonia: \",pneumonia_num)\n",
    "normal_num = len(os.listdir(os.path.join(test, 'NORMAL')))\n",
    "print(\"Normal: \",normal_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Visualization of normal chest image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dir = './input/chest_xray/train/NORMAL/'\n",
    "normal_img = os.listdir('./input/chest_xray/train/NORMAL/')[0]\n",
    "img = plt.imread(os.path.join(normal_dir, normal_img))\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"Normal\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Visualization of pneumonia effected chest image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_dir = './input/chest_xray/train/PNEUMONIA/'\n",
    "pneumonia_img = os.listdir('./input/chest_xray/train/PNEUMONIA/')[0]\n",
    "img = plt.imread(os.path.join(pneumonia_dir, pneumonia_img))\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"Pneumonia\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    samplewise_std_normalization=True,\n",
    "    samplewise_center=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Each dataset for Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = image_generator.flow_from_directory(\n",
    "    train,\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    target_size = (320, 320),\n",
    "    class_mode = 'binary',\n",
    ")\n",
    "\n",
    "test_path = image_generator.flow_from_directory(\n",
    "    test,\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    target_size = (320,320),\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "val_path = image_generator.flow_from_directory(\n",
    "    val,\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    target_size = (320, 320),\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_for_0 = pneumonia_num / (normal_num + pneumonia_num)\n",
    "weight_for_1 = normal_num / (normal_num + pneumonia_num)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "print(f\"Weight for class 0: {weight_for_0:.2f}\")\n",
    "print(f\"Weight for class 1: {weight_for_1:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential \n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "A Sequential model is not appropriate when:\n",
    "<ol>\n",
    "   <li>Your model has multiple inputs or multiple outputs</li>\n",
    "   <li>Any of your layers has multiple inputs or multiple outputs</li>\n",
    "   <li>You need to do layer sharing</li>\n",
    "   <li>You want non-linear topology (e.g. a residual connection, a multi-branch model)</li>\n",
    "</ol>   \n",
    "\n",
    "<div>\n",
    "   <img src=\"https://www.researchgate.net/profile/Rahul-Jayawardana/publication/350567223/figure/fig2/AS:1007855343792135@1617302847605/Fig-2-A-sequential-neural-model-Keras-Sequential-Api-nd-Activation-Functions-The.jpg\" width=\"500px\" height=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(2, 2), input_shape=(320,320, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=(2, 2), input_shape=(320,320, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3),  activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3),  activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_path,\n",
    "    validation_data = val_path,\n",
    "    class_weight = class_weight,\n",
    "    epochs = 5,\n",
    "    steps_per_epoch=len(train_path),\n",
    "    validation_steps=len(val_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val_Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Evolution\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.history['binary_accuracy'], label='Binary_Accuracy')\n",
    "plt.plot(history.history['val_binary_accuracy'], label='Val_Binary_Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Evolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "generated_image, label = train_path.__getitem__(0)\n",
    "plt.imshow(generated_image[0], cmap='gray')\n",
    "plt.title(\"Chest Image After CNN Modelling\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Evaluation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(\n",
    "    val_path,\n",
    "    verbose=1,\n",
    "    steps=len(val_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(val_path)\n",
    "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n",
    "evaluation_train = model.evaluate(train_path)\n",
    "print(f\"Train Accuracy: {evaluation_train[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(val_path)\n",
    "print(confusion_matrix(val_path.classes, predict > 0.5))\n",
    "pd.DataFrame(classification_report(val_path.classes, predict > 0.5, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(val_path.classes, predict > 0.7))\n",
    "pd.DataFrame(classification_report(val_path.classes, predict > 0.7, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = val_path\n",
    "images = next(im)\n",
    "images[0].shape\n",
    "results = model.predict(images[0])\n",
    "print(results)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DenseNet is a type of convolutional neural network that utilises dense connections between layers, through Dense Blocks, where we connect all layers (with matching feature-map sizes) directly with each other. To preserve the feed-forward nature, each layer obtains additional inputs from all preceding layers and passes on its own feature-maps to all subsequent layers.\n",
    "\n",
    "<div>\n",
    "<img src=\"https://production-media.paperswithcode.com/models/densenet121_spXhNmT.png\" width=\"500px\" height=\"500px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.DenseNet121(\n",
    "    include_top= False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(320,320,3),\n",
    "    pooling=\"avg\"\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_path,\n",
    "    epochs=5,\n",
    "    validation_data=val_path,\n",
    "    class_weight=class_weight,\n",
    "    steps_per_epoch=len(train_path),\n",
    "    validation_steps=len(val_path)\n",
    ")\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val_Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Evolution\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.history['binary_accuracy'], label='Binary_Accuracy')\n",
    "plt.plot(history.history['val_binary_accuracy'], label='Val_Binary_Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Evolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_denseNet = model.evaluate(val_path)\n",
    "print(f\"Test Accuracy: {evaluation_denseNet[1] * 100:.2f}%\")\n",
    "evaluation_train_denseNet = model.evaluate(train_path)\n",
    "print(f\"Train Accuracy: {evaluation_train_denseNet[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_value = model.predict(val_path, steps=len(val_path))\n",
    "print(confusion_matrix(val_path.classes, predict_value > 0.5))\n",
    "pd.DataFrame(classification_report(val_path.classes, predict_value > 0.5, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(val_path.classes, predict_value > 0.7))\n",
    "pd.DataFrame(classification_report(val_path.classes, predict_value > 0.7, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5')\n",
    "img = tf.keras.utils.load_img('./input/chest_xray/train/PNEUMONIA/person117_virus_223.jpeg', target_size = (320,320))\n",
    "imagee=tf.keras.utils.img_to_array(img)\n",
    "imagee=np.expand_dims(imagee, axis=0)\n",
    "img_data=tf.keras.applications.densenet.preprocess_input(imagee)\n",
    "prediction=model.predict(img_data)\n",
    "if prediction[0][0]>prediction[0][1]:  \n",
    "    print('Person is safe.')\n",
    "else:\n",
    "    print('Person is affected with Pneumonia.')\n",
    "print(f'Predictions: {prediction}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1acc24bd1901f9ae8c29efb6830fcc1ca9fe0219dd00f8f1dc1b91856def15a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
